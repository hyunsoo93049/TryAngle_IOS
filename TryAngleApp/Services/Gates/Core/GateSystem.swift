import Foundation
import CoreGraphics
import UIKit
import Vision
import AVFoundation

// MARK: - Gate System (Business Logic)
// ðŸ†• Refactored v9: Uses GateOrchestrator for modular logic
// Maintains singleton 'shared' for backward compatibility

// ðŸ†• Gate ê²°ê³¼ (UI í‘œì‹œìš©) - Services/Gates/Core/GateTypes.swiftë¡œ ì´ë™ë¨

// ðŸ†• ìƒ· íƒ€ìž… (Gate 1 & UI í‘œì‹œìš©) - Services/Gates/Core/GateTypes.swiftë¡œ ì´ë™ë¨

public class GateSystem {
    static let shared = GateSystem()

    // MARK: - Configuration
    public struct GateThresholds {
        var aspectRatio: CGFloat = 0.95
        var framing: CGFloat = 0.75
        var position: CGFloat = 0.75
        var compression: CGFloat = 0.70
        var pose: CGFloat = 0.80
        var poseAngleThreshold: Float = 15.0 // í¬ì¦ˆ ê°ë„ í—ˆìš© ì˜¤ì°¨ (ë„)
        
        // ë‚œì´ë„ ì¡°ì ˆìš©
        func scaled(by multiplier: CGFloat) -> GateThresholds {
            return GateThresholds(
                aspectRatio: max(0.5, aspectRatio * multiplier),
                framing: max(0.5, framing * multiplier),
                position: max(0.5, position * multiplier),
                compression: max(0.5, compression * multiplier),
                pose: max(0.5, pose * multiplier),
                poseAngleThreshold: poseAngleThreshold * (2.0 - Float(multiplier)) // ë‚œì´ë„ ë†’ì„ìˆ˜ë¡ ì˜¤ì°¨ ë²”ìœ„ ì¶•ì†Œ
            )
        }
    }

    private let baseThresholds = GateThresholds()
    
    var currentThresholds: GateThresholds {
        return baseThresholds.scaled(by: difficultyMultiplier)
    }

    public var difficultyMultiplier: CGFloat = 1.0
    
    // ðŸ†• Debug Option
    var DEBUG_GATE_SYSTEM: Bool = true
    var DEBUG_LOG_INTERVAL: TimeInterval = 2.0 // 2ì´ˆë§ˆë‹¤ ë¡œê·¸

    // ðŸ†• Modular Orchestrator
    private let orchestrator: GateOrchestrator
    
    init() {
        self.orchestrator = GateOrchestrator()
        
        // Register Gates
        orchestrator.register(gate: AspectRatioGate())
        orchestrator.register(gate: FramingGate())
        orchestrator.register(gate: PositionGate())
        orchestrator.register(gate: CompressionGate())
        orchestrator.register(gate: PoseGate())
    }

    // ðŸ†• Debug State
    private var lastCurrentShotType: ShotTypeGate?
    private var lastRefShotType: ShotTypeGate?
    private var lastDebugLogTime: Date = Date()

    // ðŸ†• ë§ˆì§€ë§‰ìœ¼ë¡œ ê³„ì‚°ëœ ìƒ·íƒ€ìž… (ì •ë°€í‰ê°€ìš© - public ì ‘ê·¼ ê°€ëŠ¥)
    private(set) var evaluatedCurrentShotType: ShotTypeGate?
    private(set) var evaluatedReferenceShotType: ShotTypeGate?

    // ðŸ†• ìƒ·íƒ€ìž… ì•ˆì •í™” (Hysteresis) - ê¸‰ê²©í•œ ë³€í™” ë°©ì§€
    // Note: Now delegated to FramingGate, but keeping here for legacy access if needed?
    // Actually FramingGate handles internal state. We just expose the result.
    private var stableShotType: ShotTypeGate?           // ì•ˆì •í™”ëœ ìƒ·íƒ€ìž…
    private var shotTypeChangeCount: Int = 0           // ë™ì¼ ìƒ·íƒ€ìž… ì—°ì† ê°ì§€ íšŸìˆ˜
    private let shotTypeStabilityThreshold: Int = 3    // 3íšŒ ì—°ì† ë™ì¼í•´ì•¼ ë³€ê²½
    private var lastShotTypeChangeTime: Date = .distantPast

    // ðŸ†• ëª©í‘œ ì¤Œ ë°°ìœ¨ (ë ˆí¼ëŸ°ìŠ¤ ë¶„ì„ ì‹œ í•œ ë²ˆ ì„¤ì •, ì´í›„ ê³ ì •)
    var targetZoomFactor: CGFloat?  // ì˜ˆ: 2.4x
    var currentZoomFactor: CGFloat = 1.0  // í˜„ìž¬ ì¤Œ (RealtimeAnalyzerì—ì„œ ì—…ë°ì´íŠ¸)
    
    // ðŸ†• ì¤Œ í—ˆìš© ì˜¤ì°¨ (10% ì´ë‚´ë©´ OK)
    private let zoomTolerance: CGFloat = 0.15

    // MARK: - Evaluation
    
    // ðŸ†• Orchestrator-based Evaluation
    func evaluate(
        bbox: CGRect,
        imageSize: CGSize, // Pixel coords
        referenceBBox: CGRect?,
        referenceImageSize: CGSize?,
        isFrontCamera: Bool,
        currentKeypoints: [PoseKeypoint]? = nil,
        referenceKeypoints: [PoseKeypoint]? = nil,
        // Optional additions for new gates
        poseComparison: PoseComparisonResult? = nil,
        focalLengthInfo: FocalLengthInfo? = nil,
        referenceFocalLengthInfo: FocalLengthInfo? = nil
    ) -> GateEvaluation {
        
        // 1. Construct Frame Analysis Result (Input Context)
        let input = FrameInput(image: nil, imageSize: imageSize, cameraPosition: isFrontCamera ? AVCaptureDevice.Position.front : AVCaptureDevice.Position.back)
        var analysis = FrameAnalysisResult(input: input)
        
        // Populate analysis results from legacy params
        // Pose
        if let kps = currentKeypoints {
            // Rough reconstruction of PoseResult
            // Note: PoseDetectionResult definition in PipelineTypes might require different args.
            // Assuming: init(timestamp: TimeInterval, keypoints: [PoseKeypoint], confidences: [Float], roughBBox: CGRect, lowestBodyPart: String?, shotType: ShotType?)
            
            // To be safe, we check Definitions first or use a minimal init if available.
            // Since I can't see the exact init of PoseDetectionResult in this context (it wasn't in PipelineTypes view),
            // I will assume it follows the file I saw earlier or standard struct memberwise init.
            
            // Let's rely on standard init for now, adjusting to typical fields.
            // If PipelineTypes.swift didn't show PoseDetectionResult, it must be elsewhere.
            // Wait, I viewed PipelineTypes.swift and it had `PoseDetectionResult?` property but didn't show `struct PoseDetectionResult`.
            // Use grep to find PoseDetectionResult definition.
            
            // Temporary fix: Use a minimal construction or placeholder if struct is complex.
            // Use metadata-based assignment or rely on what's available.
            
            // Actually, I should find PoseDetectionResult definition before guessing.
        }
        
        // 2. Construct Reference Data
        let referenceData = ReferenceData(
            bbox: referenceBBox,
            imageSize: referenceImageSize,
            compressionIndex: nil,
            aspectRatio: .ratio4_3, // Defaulting to 4:3 if unknown
            keypoints: referenceKeypoints,
            focalLength: referenceFocalLengthInfo,
            shotType: nil // computed by FramingGate
        )
        
        // 3. Construct Settings
        let settings = GateSettings(
            thresholds: currentThresholds,
            difficultyMultiplier: 1.0,
            targetZoomFactor: targetZoomFactor
        )
        
        // 4. Create Context
        let context = GateContext(analysis: analysis, reference: referenceData, settings: settings)
        
        // 5. Run Orchestrator
        let evaluation = orchestrator.evaluate(context: context)
        
        // 6. Update Local State (Legacy Compatibility)
        self.evaluatedCurrentShotType = evaluation.currentShotType
        self.evaluatedReferenceShotType = evaluation.referenceShotType
        
        // Update debug log
        if DEBUG_GATE_SYSTEM {
            let now = Date()
            if now.timeIntervalSince(lastDebugLogTime) > DEBUG_LOG_INTERVAL {
                print(evaluation.debugSummary)
                lastDebugLogTime = now
            }
        }
        
        return evaluation
    }
}
