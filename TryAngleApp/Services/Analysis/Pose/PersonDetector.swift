// PersonDetector.swift
// ì‚¬ëŒ ê²€ì¶œ - YOLOX ì „ìš© (RTMPoseRunner ì¬ì‚¬ìš©)
// ì‘ì„±ì¼: 2025-12-05
// ìˆ˜ì •ì¼: 2025-12-10 - Vision Framework ì œê±°, YOLOX ì „ìš©

import CoreML
import CoreImage
import UIKit

class PersonDetector {

    // RTMPoseRunner ì°¸ì¡° (YOLOX ì¬ì‚¬ìš©)
    private weak var rtmPoseRunner: RTMPoseRunner?

    // ğŸ”¥ CIContext ì¬ì‚¬ìš© (ë©”ëª¨ë¦¬ ìµœì í™”)
    private static let sharedContext = CIContext(options: [.cacheIntermediates: false])

    // MARK: - Initialization
    init(rtmPoseRunner: RTMPoseRunner? = nil) {
        self.rtmPoseRunner = rtmPoseRunner
        print("âœ… PersonDetector ì´ˆê¸°í™” (YOLOX ì „ìš©)")
    }

    // RTMPoseRunner ì—°ê²° (ë‚˜ì¤‘ì— ì„¤ì •)
    func setRTMPoseRunner(_ runner: RTMPoseRunner) {
        self.rtmPoseRunner = runner
        print("âœ… PersonDetector: RTMPoseRunner ì—°ê²°ë¨ (YOLOX ì‚¬ìš© ê°€ëŠ¥)")
    }

    // MARK: - Person Detection
    func detectPerson(in image: CIImage, completion: @escaping (CGRect?) -> Void) {
        // YOLOX ì „ìš©
        guard let runner = rtmPoseRunner, runner.isReady else {
            print("âš ï¸ PersonDetector: RTMPoseRunner not ready")
            completion(nil)
            return
        }
        detectPersonWithYOLOX(in: image, using: runner, completion: completion)
    }

    // MARK: - YOLOX Detection (RTMPoseRunner ì¬ì‚¬ìš©)
    private func detectPersonWithYOLOX(in image: CIImage, using runner: RTMPoseRunner, completion: @escaping (CGRect?) -> Void) {
        DispatchQueue.global(qos: .userInitiated).async {
            // CIImage â†’ UIImage ë³€í™˜ (sharedContext ì‚¬ìš©)
            guard let cgImage = Self.sharedContext.createCGImage(image, from: image.extent) else {
                DispatchQueue.main.async { completion(nil) }
                return
            }
            let uiImage = UIImage(cgImage: cgImage)

            // YOLOXë¡œ ê²€ì¶œ
            let bbox = runner.detectPersonBBox(from: uiImage)

            if let bbox = bbox {
                // YOLOX BBoxëŠ” í”½ì…€ ì¢Œí‘œ â†’ ì •ê·œí™” ì¢Œí‘œë¡œ ë³€í™˜
                let imageSize = image.extent.size
                let normalizedBBox = CGRect(
                    x: bbox.origin.x / imageSize.width,
                    y: bbox.origin.y / imageSize.height,
                    width: bbox.width / imageSize.width,
                    height: bbox.height / imageSize.height
                )

                DispatchQueue.main.async {
                    completion(normalizedBBox)
                }
            } else {
                DispatchQueue.main.async {
                    completion(nil)
                }
            }
        }
    }

    // MARK: - Multiple Person Detection
    func detectAllPersons(in image: CIImage, completion: @escaping ([Detection]) -> Void) {
        guard let runner = rtmPoseRunner, runner.isReady else {
            print("âš ï¸ PersonDetector: RTMPoseRunner not ready")
            completion([])
            return
        }
        detectAllPersonsWithYOLOX(in: image, using: runner, completion: completion)
    }

    private func detectAllPersonsWithYOLOX(in image: CIImage, using runner: RTMPoseRunner, completion: @escaping ([Detection]) -> Void) {
        DispatchQueue.global(qos: .userInitiated).async {
            guard let cgImage = Self.sharedContext.createCGImage(image, from: image.extent) else {
                DispatchQueue.main.async { completion([]) }
                return
            }
            let uiImage = UIImage(cgImage: cgImage)
            let imageSize = image.extent.size

            let boxes = runner.detectAllPersonBBoxes(from: uiImage)

            let detections = boxes.map { bbox -> Detection in
                // í”½ì…€ ì¢Œí‘œ â†’ ì •ê·œí™” ì¢Œí‘œ
                let normalizedBBox = CGRect(
                    x: bbox.origin.x / imageSize.width,
                    y: bbox.origin.y / imageSize.height,
                    width: bbox.width / imageSize.width,
                    height: bbox.height / imageSize.height
                )
                return Detection(label: "person", confidence: 0.9, boundingBox: normalizedBBox)
            }

            DispatchQueue.main.async {
                completion(detections)
            }
        }
    }

    // MARK: - Text-Guided Detection (í˜¸í™˜ì„± ìœ ì§€)
    func detectWithText(in image: CIImage, text: String, completion: @escaping ([Detection]) -> Void) {
        if text.lowercased().contains("person") || text.lowercased().contains("ì‚¬ëŒ") {
            detectAllPersons(in: image, completion: completion)
        } else {
            print("âš ï¸ í˜„ì¬ 'person' ê²€ì¶œë§Œ ì§€ì›ë©ë‹ˆë‹¤")
            completion([])
        }
    }

    // MARK: - Model Info
    var isUsingYOLOX: Bool {
        return rtmPoseRunner?.isReady ?? false
    }

    var modelDescription: String {
        return "YOLOX (RTMPoseRunner ì¬ì‚¬ìš©)"
    }
}

// MARK: - Detection Result
struct Detection {
    let label: String
    let confidence: Float
    let boundingBox: CGRect
}

// MARK: - Legacy System Port
extension PersonDetector {

    // legacy_analyzer.pyì˜ calculate_marginsë¥¼ Swiftë¡œ í¬íŒ…
    func calculateMargins(personBBox: CGRect, imageSize: CGSize) -> MarginAnalysis {
        let imageWidth = imageSize.width
        let imageHeight = imageSize.height

        // bboxë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜ (Vision/YOLOXëŠ” normalized coordinates ì‚¬ìš©)
        let x = personBBox.origin.x * imageWidth
        let y = personBBox.origin.y * imageHeight
        let w = personBBox.width * imageWidth
        let h = personBBox.height * imageHeight

        // ì—¬ë°± ê³„ì‚°
        let leftMargin = x
        let rightMargin = imageWidth - (x + w)
        let topMargin = y
        let bottomMargin = imageHeight - (y + h)

        // ë¹„ìœ¨ ê³„ì‚°
        let leftRatio = leftMargin / imageWidth
        let rightRatio = rightMargin / imageWidth
        let topRatio = topMargin / imageHeight
        let bottomRatio = bottomMargin / imageHeight

        // ê· í˜• ì ìˆ˜ ê³„ì‚°
        let horizontalBalance = 1.0 - abs(leftRatio - rightRatio)
        let verticalBalance = 1.0 - abs(topRatio - bottomRatio * 0.5) // í•˜ë‹¨ 2:1 ë¹„ìœ¨ ì„ í˜¸
        let balanceScore = (horizontalBalance + verticalBalance) / 2.0

        return MarginAnalysis(
            left: leftMargin,
            right: rightMargin,
            top: topMargin,
            bottom: bottomMargin,
            leftRatio: leftRatio,
            rightRatio: rightRatio,
            topRatio: topRatio,
            bottomRatio: bottomRatio,
            balanceScore: balanceScore
        )
    }

    // í”„ë ˆì´ë° ë¶„ì„
    func analyzeFraming(personBBox: CGRect, imageSize: CGSize) -> V15FramingAnalysis {
        let margins = calculateMargins(personBBox: personBBox, imageSize: imageSize)

        // í”„ë ˆì´ë° íƒ€ì… ê²°ì •
        let framingType: V15FramingType
        let bboxHeightRatio = personBBox.height

        if bboxHeightRatio > 0.8 {
            framingType = .tooTight
        } else if bboxHeightRatio < 0.3 {
            framingType = .tooLoose
        } else if bboxHeightRatio > 0.6 {
            framingType = .closeUp
        } else if bboxHeightRatio > 0.4 {
            framingType = .medium
        } else {
            framingType = .wide
        }

        // í¬ë¡­ ì´ìŠˆ ì²´í¬
        let hasCropIssue = margins.left < 10 || margins.right < 10 ||
                           margins.top < 10 || margins.bottom < 10

        return V15FramingAnalysis(
            type: framingType,
            score: margins.balanceScore,
            hasCropIssue: hasCropIssue,
            margins: margins
        )
    }
}

// MARK: - Data Structures
struct MarginAnalysis {
    let left: CGFloat
    let right: CGFloat
    let top: CGFloat
    let bottom: CGFloat
    let leftRatio: CGFloat
    let rightRatio: CGFloat
    let topRatio: CGFloat
    let bottomRatio: CGFloat
    let balanceScore: CGFloat
}

struct V15FramingAnalysis {
    let type: V15FramingType
    let score: CGFloat
    let hasCropIssue: Bool
    let margins: MarginAnalysis
}

enum V15FramingType {
    case tooTight
    case tooLoose
    case closeUp
    case medium
    case wide
}
