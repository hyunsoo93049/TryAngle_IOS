import Foundation
import UIKit

// MARK: - RTMPose Service Adapter
// Ïó≠Ìï†: RTMPoseRunner Ïã±Í∏ÄÌÜ§ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Ìè¨Ï¶à Í≤ÄÏ∂ú ÏÑúÎπÑÏä§Î•º Ï†úÍ≥µÌï©ÎãàÎã§.
//       PoseDetector ÌîÑÎ°úÌÜ†ÏΩúÏùÑ Íµ¨ÌòÑÌïòÏó¨ DetectionPipelineÏóêÏÑú ÏÇ¨Ïö©Îê©ÎãàÎã§.
//       Ïã§ÏãúÍ∞Ñ Î∂ÑÏÑùÏö© ÏñºÍµ¥+Ìè¨Ï¶à ÎèôÏãú Î∂ÑÏÑù Í∏∞Îä•ÎèÑ Ï†úÍ≥µÌï©ÎãàÎã§.

public class RTMPoseService: PoseDetector {

    // MARK: - Singleton
    public static let shared = RTMPoseService()

    public let name = "RTMPose"
    public var isEnabled: Bool = true

    // Ïã±Í∏ÄÌÜ§ Runner ÏÇ¨Ïö©
    private var runner: RTMPoseRunner? { RTMPoseRunner.shared }

    public init() {}

    public func initialize() async throws {
        // Ïã±Í∏ÄÌÜ§Ïù¥ÎØÄÎ°ú Î≥ÑÎèÑ Ï¥àÍ∏∞Ìôî Î∂àÌïÑÏöî (Ïï± ÏãúÏûë Ïãú Ïù¥ÎØ∏ Ï¥àÍ∏∞ÌôîÎê®)
        print("üöÄ RTMPoseService initializing (using shared RTMPoseRunner)...")

        guard runner != nil else {
            throw NSError(domain: "RTMPoseService", code: -1, userInfo: [NSLocalizedDescriptionKey: "RTMPoseRunner.shared is nil"])
        }
        print("‚úÖ RTMPoseService initialized successfully (shared runner).")
    }
    
    public func detect(input: FrameInput) async throws -> PoseDetectionResult? {
        guard isEnabled, let runner = runner else { return nil }
        
        // Ïù¥ÎØ∏ÏßÄ Î∞©Ìñ• Ï≤òÎ¶¨? RTMPoseRunnerÎäî .upÏùÑ Í∞ºÏ†ïÌïòÎäî Í≤ΩÏö∞Í∞Ä ÎßéÏùå.
        // ÌòÑÏû¨Îäî input.imageÎ•º Í∑∏ÎåÄÎ°ú Ï†ÑÎã¨.
        
        return try await withCheckedThrowingContinuation { continuation in
            DispatchQueue.global(qos: .userInitiated).async {
                // 1. Pose Inference
                guard let image = input.image,
                      let result = runner.detectPose(from: image) else {
                    // Í∞êÏßÄ Ïã§Ìå® ÎòêÎäî ÏÇ¨Îûå ÏóÜÏùå
                    continuation.resume(returning: nil)
                    return
                }
                
                // 2. Convert raw keypoints to Result format
                // RTMPoseResult uses (point: CGPoint, confidence: Float)
                let keypoints = result.keypoints.map { $0.point }
                let confidences = result.keypoints.map { $0.confidence }
                let bbox = result.boundingBox ?? CGRect.zero
                
                // 3. Optional: Calculate ShotType/LowestPart logic here or in a separate analyzer.
                // For now, we perform basic analysis to populate the fields.
                // We'll reuse the logic from GateSystem/ShotTypeGate logically here.
                
                let analysis = self.analyzePose(keypoints: result.keypoints)
                
                let poseResult = PoseDetectionResult(
                    timestamp: input.timestamp,
                    keypoints: keypoints,
                    confidences: confidences,
                    roughBBox: bbox,
                    lowestBodyPart: analysis.lowestPart,
                    shotType: analysis.shotType
                )
                
                continuation.resume(returning: poseResult)
            }
        }
    }
    
    // MARK: - Local Analysis Helpers (Ported/Simplified from GateSystem)
    
    private struct PoseAnalysis {
        let lowestPart: String
        let shotType: String
    }
    
    private func analyzePose(keypoints: [(point: CGPoint, confidence: Float)]) -> PoseAnalysis {
        // 17Í∞ú ÌÇ§Ìè¨Ïù∏Ìä∏(COCO format) Í∏∞Ï§Ä Î∂ÑÏÑù
        // 0:nose, 1:LEye, 2:REye, 3:LEar, 4:REar, 5:LShoulder, 6:RShoulder
        // 7:LElbow, 8:RElbow, 9:LWrist, 10:RWrist, 11:LHip, 12:RHip
        // 13:LKnee, 14:RKnee, 15:LAnkle, 16:RAnkle
        
        guard keypoints.count >= 17 else { return PoseAnalysis(lowestPart: "unknown", shotType: "unknown") }
        
        func isVisible(_ idx: Int) -> Bool {
            return keypoints[idx].confidence > 0.3
        }
        
        // Find lowest visible part
        // y Ï¢åÌëúÍ∞Ä ÌÅ¥ÏàòÎ°ù ÏïÑÎûòÏ™Ω (Vision Ï¢åÌëúÍ≥ÑÍ∞Ä ÏïÑÎãå UIKit Ï¢åÌëúÍ≥Ñ Í∏∞Ï§Ä: Top-LeftÍ∞Ä 0,0)
        // RTMPoseResultÎäî Ï†ïÍ∑úÌôîÎêú Ï¢åÌëú(0~1)Î•º Î∞òÌôòÌïúÎã§Í≥† Í∞ÄÏ†ï (Runner ÏΩîÎìú ÌôïÏù∏ ÌïÑÏöî)
        // RTMPoseRunner.swift:540 -> point = ... / imageSize (0~1 normalized)
        
        var lowestY: CGFloat = 0.0
        var lowestPart = "face"
        
        let parts = [
            ("ankle", [15, 16]),
            ("knee", [13, 14]),
            ("hip", [11, 12]),
            ("elbow", [7, 8]),
            ("shoulder", [5, 6]),
            ("face", [0])
        ]
        
        for (name, indices) in parts {
            for idx in indices {
                if isVisible(idx) {
                    let y = keypoints[idx].point.y
                    if y > lowestY {
                        lowestY = y
                        lowestPart = name
                    }
                }
            }
        }
        
        // Shot Type Logic (Simplified)
        var shotType = "unknown"
        switch lowestPart {
        case "ankle": shotType = "fullShot"
        case "knee": shotType = "mediumFullShot"
        case "hip": shotType = "mediumShot" // Or americanShot if no elbows
        case "elbow": shotType = "mediumCloseUp"
        case "shoulder": shotType = "closeUp"
        case "face": shotType = "extremeCloseUp"
        default: shotType = "unknown"
        }
        
        return PoseAnalysis(lowestPart: lowestPart, shotType: shotType)
    }

    // MARK: - Ïã§ÏãúÍ∞Ñ Î∂ÑÏÑùÏö© ÏñºÍµ¥+Ìè¨Ï¶à ÎèôÏãú Î∂ÑÏÑù (ÎèôÍ∏∞ Î≤ÑÏ†Ñ)

    /// ÏñºÍµ¥ + Ìè¨Ï¶à ÎèôÏãú Î∂ÑÏÑù (RealtimeAnalyzerÏóêÏÑú ÏÇ¨Ïö©)
    func analyzeFaceAndPose(from image: UIImage) -> (face: FaceAnalysisResult?, pose: PoseAnalysisResult?) {
        guard let runner = runner else {
            return (nil, nil)
        }

        // RTMPoseÎ°ú Ìè¨Ï¶à Í∞êÏßÄ
        guard let rtmResult = runner.detectPose(from: image) else {
            return (nil, nil)
        }

        // PoseAnalysisResult ÏÉùÏÑ±
        let poseResult = PoseAnalysisResult(keypoints: rtmResult.keypoints)

        // ÏñºÍµ¥ Ï†ïÎ≥¥ Ï∂îÏ∂ú (RTMPose ÌÇ§Ìè¨Ïù∏Ìä∏ Í∏∞Î∞ò)
        let faceResult = extractFaceFromPose(poseResult: poseResult, imageSize: image.size)

        return (faceResult, poseResult)
    }

    // MARK: - RTMPose ÌÇ§Ìè¨Ïù∏Ìä∏ÏóêÏÑú ÏñºÍµ¥ Ï†ïÎ≥¥ Ï∂îÏ∂ú

    private func extractFaceFromPose(poseResult: PoseAnalysisResult?, imageSize: CGSize) -> FaceAnalysisResult? {
        guard let pose = poseResult, pose.keypoints.count >= 23 else {
            return nil
        }

        // RTMPose ÏñºÍµ¥ ÌÇ§Ìè¨Ïù∏Ìä∏ (23~90Î≤à): 68Í∞ú
        let faceKeypoints = Array(pose.keypoints[23..<min(91, pose.keypoints.count)])

        // Ïã†Î¢∞ÎèÑ ÏûàÎäî ÏñºÍµ¥ ÌÇ§Ìè¨Ïù∏Ìä∏ ÌïÑÌÑ∞ÎßÅ
        let validFacePoints = faceKeypoints.filter { $0.confidence > 0.3 }
        guard validFacePoints.count >= 5 else {
            return nil  // ÏµúÏÜå 5Í∞ú Ïù¥ÏÉÅÏùò ÌÇ§Ìè¨Ïù∏Ìä∏ ÌïÑÏöî
        }

        // ÏñºÍµ¥ Î∞îÏö¥Îî© Î∞ïÏä§ Í≥ÑÏÇ∞
        let facePoints = validFacePoints.map { $0.point }
        let minX = facePoints.map { $0.x }.min() ?? 0
        let maxX = facePoints.map { $0.x }.max() ?? 0
        let minY = facePoints.map { $0.y }.min() ?? 0
        let maxY = facePoints.map { $0.y }.max() ?? 0

        // Ï†ïÍ∑úÌôîÎêú Ï¢åÌëúÎ°ú Î≥ÄÌôò (0.0 ~ 1.0)
        let faceRect = CGRect(
            x: minX / imageSize.width,
            y: minY / imageSize.height,
            width: (maxX - minX) / imageSize.width,
            height: (maxY - minY) / imageSize.height
        )

        // yaw, pitch, roll Ï∂îÏ†ï (RTMPose Îàà/ÏΩî/ÏûÖ ÌÇ§Ìè¨Ïù∏Ìä∏ÏóêÏÑú)
        let (yaw, pitch, roll) = estimateFaceAngles(from: pose.keypoints, imageSize: imageSize)

        return FaceAnalysisResult(
            faceRect: faceRect,
            landmarks: nil,  // Vision landmarks ÏóÜÏùå
            yaw: yaw,
            pitch: pitch,
            roll: roll,
            observation: nil  // VNFaceObservation ÏóÜÏùå
        )
    }

    // MARK: - ÏñºÍµ¥ Í∞ÅÎèÑ Ï∂îÏ†ï (RTMPose ÌÇ§Ìè¨Ïù∏Ìä∏ Í∏∞Î∞ò)

    private func estimateFaceAngles(from keypoints: [(point: CGPoint, confidence: Float)], imageSize: CGSize) -> (Float?, Float?, Float?) {
        guard keypoints.count >= 17 else { return (nil, nil, nil) }

        // Îàà ÌÇ§Ìè¨Ïù∏Ìä∏ (1: left_eye, 2: right_eye)
        let leftEye = keypoints[1]
        let rightEye = keypoints[2]
        let nose = keypoints[0]

        guard leftEye.confidence > 0.5, rightEye.confidence > 0.5 else {
            return (nil, nil, nil)
        }

        // Roll (Ï¢åÏö∞ Í∏∞Ïö∏Í∏∞): Îëê ÎààÏùò y Ï∞®Ïù¥
        let eyeDy = leftEye.point.y - rightEye.point.y
        let eyeDx = leftEye.point.x - rightEye.point.x
        let roll = atan2(eyeDy, eyeDx)  // ÎùºÎîîÏïà

        // Yaw (Ï¢åÏö∞ ÌöåÏ†Ñ): Îëê ÎààÏùò x Í±∞Î¶¨ ÎπÑÏú®
        let eyeDistance = abs(leftEye.point.x - rightEye.point.x)
        let faceWidth = imageSize.width * 0.3  // ÌèâÍ∑† ÏñºÍµ¥ ÎÑàÎπÑ
        let yaw = (eyeDistance - faceWidth) / faceWidth * 0.5  // Ï†ïÍ∑úÌôî

        // Pitch (ÏÉÅÌïò Í∞ÅÎèÑ): ÏΩîÏôÄ ÎààÏùò y Ï∞®Ïù¥
        let pitch: Float? = nose.confidence > 0.5 ? Float((nose.point.y - leftEye.point.y) / imageSize.height) : nil

        return (Float(yaw), pitch, Float(roll))
    }

    // MARK: - Ïú†Ìã∏Î¶¨Ìã∞

    /// Î∞ùÍ∏∞ Í≥ÑÏÇ∞
    public func calculateBrightness(from cgImage: CGImage) -> Float {
        let width = min(cgImage.width, 100)
        let height = min(cgImage.height, 100)

        guard let context = CGContext(
            data: nil,
            width: width,
            height: height,
            bitsPerComponent: 8,
            bytesPerRow: width * 4,
            space: CGColorSpaceCreateDeviceRGB(),
            bitmapInfo: CGImageAlphaInfo.premultipliedLast.rawValue
        ) else { return 0.5 }

        context.draw(cgImage, in: CGRect(x: 0, y: 0, width: width, height: height))
        guard let data = context.data else { return 0.5 }

        let buffer = data.bindMemory(to: UInt8.self, capacity: width * height * 4)
        var totalBrightness: Float = 0

        for i in stride(from: 0, to: width * height * 4, by: 4) {
            let r = Float(buffer[i]) / 255.0
            let g = Float(buffer[i + 1]) / 255.0
            let b = Float(buffer[i + 2]) / 255.0
            totalBrightness += (r + g + b) / 3.0
        }

        return totalBrightness / Float(width * height)
    }

    /// Ï†ÑÏã† ÏòÅÏó≠ Ï∂îÏ†ï (fallbackÏö©)
    public func estimateBodyRect(from faceRect: CGRect?) -> CGRect? {
        guard let face = faceRect else { return nil }

        let bodyWidth = face.width * 3
        let bodyHeight = face.height * 7
        let bodyX = face.midX - bodyWidth / 2
        let bodyY = face.minY

        return CGRect(x: bodyX, y: bodyY, width: bodyWidth, height: bodyHeight)
    }
}
