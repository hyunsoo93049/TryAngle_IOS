import Foundation
import UIKit

// MARK: - RTMPose Service Adapter

public class RTMPoseService: PoseDetector {
    public let name = "RTMPose"
    public var isEnabled: Bool = true
    
    // ê¸°ì¡´ Runner ìž¬ì‚¬ìš©
    private var runner: RTMPoseRunner?
    
    public init() {}
    
    public func initialize() async throws {
        // ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì´ˆê¸°í™” (ONNX ëª¨ë¸ ë¡œë”© ë“±)
        print("ðŸš€ RTMPoseService initializing...")
        
        return try await withCheckedThrowingContinuation { continuation in
            DispatchQueue.global(qos: .userInitiated).async { [weak self] in
                if let runner = RTMPoseRunner() {
                    self?.runner = runner
                    print("âœ… RTMPoseService initialized successfully.")
                    continuation.resume()
                } else {
                    continuation.resume(throwing: NSError(domain: "RTMPoseService", code: -1, userInfo: [NSLocalizedDescriptionKey: "Failed to initialize RTMPoseRunner"]))
                }
            }
        }
    }
    
    public func detect(input: FrameInput) async throws -> PoseDetectionResult? {
        guard isEnabled, let runner = runner else { return nil }
        
        // ì´ë¯¸ì§€ ë°©í–¥ ì²˜ë¦¬? RTMPoseRunnerëŠ” .upì„ ê°¼ì •í•˜ëŠ” ê²½ìš°ê°€ ë§ŽìŒ.
        // í˜„ìž¬ëŠ” input.imageë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬.
        
        return try await withCheckedThrowingContinuation { continuation in
            DispatchQueue.global(qos: .userInitiated).async {
                // 1. Pose Inference
                guard let result = runner.detectPose(from: input.image),
                      let firstPerson = result.first else {
                    // ê°ì§€ ì‹¤íŒ¨ ë˜ëŠ” ì‚¬ëžŒ ì—†ìŒ
                    continuation.resume(returning: nil)
                    return
                }
                
                // 2. Convert raw keypoints to Result format
                // RTMPoseResult uses (point: CGPoint, confidence: Float)
                let keypoints = firstPerson.keypoints.map { $0.point }
                let confidences = firstPerson.keypoints.map { $0.confidence }
                let bbox = firstPerson.boundingBox ?? CGRect.zero
                
                // 3. Optional: Calculate ShotType/LowestPart logic here or in a separate analyzer.
                // For now, we perform basic analysis to populate the fields.
                // We'll reuse the logic from GateSystem/ShotTypeGate logically here.
                
                let analysis = self.analyzePose(keypoints: firstPerson.keypoints)
                
                let poseResult = PoseDetectionResult(
                    timestamp: input.timestamp,
                    keypoints: keypoints,
                    confidences: confidences,
                    roughBBox: bbox,
                    lowestBodyPart: analysis.lowestPart,
                    shotType: analysis.shotType
                )
                
                continuation.resume(returning: poseResult)
            }
        }
    }
    
    // MARK: - Local Analysis Helpers (Ported/Simplified from GateSystem)
    
    private struct PoseAnalysis {
        let lowestPart: String
        let shotType: String
    }
    
    private func analyzePose(keypoints: [(point: CGPoint, confidence: Float)]) -> PoseAnalysis {
        // 17ê°œ í‚¤í¬ì¸íŠ¸(COCO format) ê¸°ì¤€ ë¶„ì„
        // 0:nose, 1:LEye, 2:REye, 3:LEar, 4:REar, 5:LShoulder, 6:RShoulder
        // 7:LElbow, 8:RElbow, 9:LWrist, 10:RWrist, 11:LHip, 12:RHip
        // 13:LKnee, 14:RKnee, 15:LAnkle, 16:RAnkle
        
        guard keypoints.count >= 17 else { return PoseAnalysis(lowestPart: "unknown", shotType: "unknown") }
        
        func isVisible(_ idx: Int) -> Bool {
            return keypoints[idx].confidence > 0.3
        }
        
        // Find lowest visible part
        // y ì¢Œí‘œê°€ í´ìˆ˜ë¡ ì•„ëž˜ìª½ (Vision ì¢Œí‘œê³„ê°€ ì•„ë‹Œ UIKit ì¢Œí‘œê³„ ê¸°ì¤€: Top-Leftê°€ 0,0)
        // RTMPoseResultëŠ” ì •ê·œí™”ëœ ì¢Œí‘œ(0~1)ë¥¼ ë°˜í™˜í•œë‹¤ê³  ê°€ì • (Runner ì½”ë“œ í™•ì¸ í•„ìš”)
        // RTMPoseRunner.swift:540 -> point = ... / imageSize (0~1 normalized)
        
        var lowestY: CGFloat = 0.0
        var lowestPart = "face"
        
        let parts = [
            ("ankle", [15, 16]),
            ("knee", [13, 14]),
            ("hip", [11, 12]),
            ("elbow", [7, 8]),
            ("shoulder", [5, 6]),
            ("face", [0])
        ]
        
        for (name, indices) in parts {
            for idx in indices {
                if isVisible(idx) {
                    let y = keypoints[idx].point.y
                    if y > lowestY {
                        lowestY = y
                        lowestPart = name
                    }
                }
            }
        }
        
        // Shot Type Logic (Simplified)
        var shotType = "unknown"
        switch lowestPart {
        case "ankle": shotType = "fullShot"
        case "knee": shotType = "mediumFullShot"
        case "hip": shotType = "mediumShot" // Or americanShot if no elbows
        case "elbow": shotType = "mediumCloseUp"
        case "shoulder": shotType = "closeUp"
        case "face": shotType = "extremeCloseUp"
        default: shotType = "unknown"
        }
        
        return PoseAnalysis(lowestPart: lowestPart, shotType: shotType)
    }
}
